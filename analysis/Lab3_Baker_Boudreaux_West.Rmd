---
title: "W203 Section 0904 Lab 3: Reducing Crime"
author: "Jason Baker, John Boudreaux, Alex West"
date: "11/23/2018"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

How do you reduce crime? Leaders have wrestled with this question since the dawn of civilization, focusing on all elements of society from education, to economics, to criminal punishment. The candidate released a platform that includes public safety as a core component, and hired our firm to analyze the data and present policy recommendations. The dataset includes variables describing multiple facets of the North Carolina population, including demographics, law enforcement, criminal punishment, population density, earnings, and more. Our approach is to examine the dependent variable, crime rate, against only those variables that we believe can be specifically affected by public sector resources, which therefore have public policy solutions. 

#### Research question:
Can the crime rate be reduced by public sector resources? Do we have direct levers to influence crime rate? 

## Data Loading and Cleaning
Our data come from a 1994 study from Cornwell and Trumball, who collected various panel data from counties across North Carolina. We will use R (>= 3.4.3) in order to analyze our data and create models.

We first load in the data to our session, and run some basic summary commands to get a broad understanding of the data.

```{r}
data <- read.csv("../data/crime_v2.csv")
# summary(data) # alternate means to explore data
str(data)

```

We can see that our data primarily has numerical fields, some of which are binary categorical variables (west, central, urban) with values of 0 and 1. Because we will be performing a linear regression, it will be useful to keep these as numerical variables rather than discrete factors. Since the ‘county’ and ‘year’ variables only act as identifying labels on our data, we can remove these from our data frame to reduce its size with no adverse effects to our working data. We will save these into vectors that we can reference later, should the need arise.

```{r}
county <- data$county
data$county <- NULL
year <- data$year
data$year <- NULL
```

A next logical step for us is to look into the “prbconv” variable, and why it is being treated as a factor instead of a numeric.

```{r}
data$prbconv
```

We can see that there are entries that are not numeric, with entries of commas, apostrophes, and other characters. Unfortunately, considering we expect this field to be column to be numerical values, we should treat these as missing data since it is likely entered incorrectly. For our analysis, we will simply replace them with NA values. We can do this while converting all of the numeric values into R-numeric format with the following command, which will coerce all the non-numerics to NA.

```{r}
data$prbconv <- as.numeric(as.character(data$prbconv))
```
At this point, we should look at the missing values throughout our data. We will do this by searching for the missing rows in each column of the data frame.

```{r}
na.rows <- lapply(data, function(x){which(is.na(x))})
na.rows
```

Rows 92 through 97 are missing values for nearly every column in our data. Given this, we should be skeptical about the information that the existing values give us in these rows. For our analysis, we will drop all of these rows entirely since we do not know the exact methods in which these data were collected.

```{r}
data <- data[-c(92:97),]
```

While our group analyzed boxplots and histograms for all variables in our data, we will only highlight a few for the sake of brevity. We should point out the “prbconv” variable, which is supposed to be the probability of a conviction given an arrest. Because this is a probability, it does not make sense to have any values above a value of 1. We manually set these values to NA.

```{r}
# command for running all boxplots, histograms for all variables 
# for(i in 1:ncol(data)){
#   if(is.numeric(data[[i]])){
#     hist(data[[i]], breaks = 15, main = colnames(data)[i])
#     boxplot(data[[i]], main = colnames(data)[i]
#   }
# }

# commands for exploring prbconv
hist(data$prbconv, breaks = 20, main = "prbconv")
data$prbconv[data$prbconv > 1] <- NA
```

While there are statistical outliers in nearly all of our variables according to the boxplots, which calculate outliers as 1.5 +- IQR, we cannot simply eliminate all statistical outliers because we do not have a grasp on the realistic boundaries of these data. Given we do not have much information about the collection methods, we choose to keep the majority of these “outliers” considering we do not have information that says they are not reflective of reality.

There is one exception to the comments above, however. With the “wser” variable, we see that there is a single outlier that lies extremely far away from the rest of the data (hypothesis test here? maybe?). Our group finds this point to be very suspect, and will remove it from further analysis.

```{r}
mean(data$wser, na.rm = TRUE)
median(data$wser, na.rm = TRUE)
boxplot(data$wser)


# let's set our major outlier to NA just for wser
data$wser[data$wser > 1500] <- NA

```
